{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUqDG1wyjHQn"
      },
      "outputs": [],
      "source": [
        "pip install sklearn_crfsuite"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets"
      ],
      "metadata": {
        "id": "4VHMNwS3jOC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn_crfsuite import CRF\n",
        "from sklearn.metrics import classification_report\n",
        "import random\n",
        "import itertools\n",
        "import numpy as np\n",
        "import scipy\n",
        "from sklearn import metrics\n",
        "from sklearn_crfsuite.utils import flatten\n",
        "from datasets import load_dataset\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "57pEtDs1jfDV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Dataset"
      ],
      "metadata": {
        "id": "I9sYTkU4jueB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"conll2003\")\n",
        "train_set = dataset[\"train\"]\n",
        "validation_set = dataset[\"validation\"]\n",
        "test_set = dataset[\"test\"]"
      ],
      "metadata": {
        "id": "wOcpK_Xcjitj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A function to convert digit labels to string labels\n",
        "def convert_ner_tags(dataset):\n",
        "  # Label mapping from integer to string\n",
        "  label_map = {0: 'O', 1: 'PER', 2: 'B-PER', 3: 'I-PER', 4: 'B-ORG', 5: 'I-ORG', 6: 'B-LOC', 7: 'I-LOC', 8: 'B-MISC', 9: 'I-MISC'}\n",
        "  list_sent = []\n",
        "  list_labels = []\n",
        "  for sent in dataset:\n",
        "    words = []\n",
        "    label = []\n",
        "    for word, label_idx in zip(sent['tokens'], sent['ner_tags']):\n",
        "        label.append(label_map[label_idx])\n",
        "        words.append(word)\n",
        "    list_sent.append(words)\n",
        "    list_labels.append(label)\n",
        "  return list_sent, list_labels"
      ],
      "metadata": {
        "id": "0KGgwQE9jxfr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the train, validation and test set\n",
        "train_ner, train_label_ner = convert_ner_tags(train_set)\n",
        "validation_ner, validation_label_ner  = convert_ner_tags(validation_set)\n",
        "test_ner, test_label_ner = convert_ner_tags(test_set)"
      ],
      "metadata": {
        "id": "IJ5OZFcXj1TV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train',len(train_ner),len(train_label_ner))\n",
        "print('Test',len(test_ner),len(test_label_ner))\n",
        "print('Validation',len(validation_ner),len(validation_label_ner))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPl-wQCSj3sz",
        "outputId": "1bc6b604-14c6-44de-c61f-07d7e8f248e6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train 14041 14041\n",
            "Test 3453 3453\n",
            "Validation 3250 3250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Increase size of train set\n",
        "new_train = []\n",
        "new_train.extend(train_ner)\n",
        "new_train.extend(validation_ner)\n",
        "\n",
        "new_label = []\n",
        "new_label.extend(train_label_ner)\n",
        "new_label.extend(validation_label_ner)\n",
        "\n",
        "print('Full',len(new_train),len(new_label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQjzVMyb1joA",
        "outputId": "d140c754-96cc-4f5a-db94-7cb488c3a793"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full 17291 17291\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train CRF Model"
      ],
      "metadata": {
        "id": "wzU5oVL6j_WQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the CRF model with class weighting\n",
        "crf = CRF(algorithm='lbfgs', c1=0.25, c2=0.03, max_iterations=400, all_possible_states=True)\n",
        "crf.fit(new_train, new_label)\n",
        "labels = list(crf.classes_)"
      ],
      "metadata": {
        "id": "ok3l1CJTj54U"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "TOcOp5wfkh0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = crf.predict(test_ner)\n",
        "print(test_label_ner[0])\n",
        "print(y_pred[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2iY1KNikEeR",
        "outputId": "eff96f5e-0a21-46b8-c29a-b1bcf0bd1a16"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['O', 'O', 'I-ORG', 'O', 'O', 'O', 'O', 'PER', 'O', 'O', 'O', 'O']\n",
            "['I-PER', 'O', 'I-ORG', 'O', 'I-PER', 'B-ORG', 'O', 'I-ORG', 'O', 'I-ORG', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate evaluation metrics\n",
        "report = classification_report(flatten(test_label_ner), flatten(y_pred), digits=3)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zi7461fakIuB",
        "outputId": "807c49e6-fdc5-4b4e-eb52-1ac123ee48cc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC      0.280     0.128     0.176       257\n",
            "      B-MISC      0.157     0.185     0.170       216\n",
            "       B-ORG      0.250     0.166     0.200       835\n",
            "       B-PER      0.519     0.556     0.537      1156\n",
            "       I-LOC      0.212     0.068     0.103       702\n",
            "       I-ORG      0.407     0.330     0.365      1668\n",
            "       I-PER      0.390     0.184     0.250      1661\n",
            "           O      0.910     0.965     0.937     38323\n",
            "         PER      0.510     0.400     0.448      1617\n",
            "\n",
            "    accuracy                          0.848     46435\n",
            "   macro avg      0.404     0.331     0.354     46435\n",
            "weighted avg      0.820     0.848     0.831     46435\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score, cross_val_predict, RandomizedSearchCV"
      ],
      "metadata": {
        "id": "WrJSvCfN_oTv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = list(filter(lambda a: a != 'O', labels))\n",
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gqfEOiNLYhL",
        "outputId": "7d81bcd3-18cf-4123-8069-40f7b9230a3f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I-PER', 'I-LOC', 'PER', 'B-PER', 'I-ORG', 'B-ORG', 'B-MISC', 'B-LOC']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "crf3 = CRF(\n",
        "    algorithm='lbfgs',\n",
        "    max_iterations=100,\n",
        "    all_possible_transitions=True\n",
        ")\n",
        "params_space = {\n",
        "    'c1': scipy.stats.expon(scale=0.5),\n",
        "    'c2': scipy.stats.expon(scale=0.05),\n",
        "}\n",
        "\n",
        "rs = RandomizedSearchCV(crf, params_space,\n",
        "                        cv=3,\n",
        "                        verbose=1,\n",
        "                        n_jobs=-1,\n",
        "                        n_iter=50,\n",
        "                        scoring='f1_macro')\n",
        "\n",
        "rs.fit(new_train, new_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "hGADPmdEMvG2",
        "outputId": "9a1e0366-9c5a-4234-ec4e-73a716213b21"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0mn_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_orig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0mbase_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mnew_object_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_object_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mnew_object_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"get_params\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0mdeep_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'CRF' object has no attribute 'keep_tempfiles'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_set = []\n",
        "full_set.extend(train_ner)\n",
        "full_set.extend(validation_ner)\n",
        "full_set.extend(test_ner)\n",
        "\n",
        "full_label = []\n",
        "full_label.extend(train_label_ner)\n",
        "full_label.extend(validation_label_ner)\n",
        "full_label.extend(test_label_ner)"
      ],
      "metadata": {
        "id": "gfW_VUq0m3of"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.base import clone\n",
        "\n",
        "def randomized_search_cv(param_distributions, X_train, y_train,  n_iter, cv):\n",
        "    best_score = None\n",
        "    best_params = None\n",
        "    it = 0\n",
        "    for _ in range(n_iter):\n",
        "        print(\"\\n\\n§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§ Iteration \", it, \"§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§\")\n",
        "        ii=0\n",
        "        for param_name, distribution in param_distributions.items():\n",
        "            param_value = distribution.rvs()\n",
        "            if ii == 0:\n",
        "              c_one = param_value\n",
        "            else:\n",
        "              c_two = param_value\n",
        "            ii += 1\n",
        "\n",
        "        estimator = CRF(algorithm='lbfgs', c1= c_one, c2= c_two, max_iterations=300, all_possible_transitions=True)\n",
        "\n",
        "        cv_results = []\n",
        "        f = 0\n",
        "        for train_index, test_index in cv.split(X_train):\n",
        "            X_train_fold, X_val_fold = np.array(X_train)[train_index], np.array(X_train)[test_index]\n",
        "            y_train_fold, y_val_fold = np.array(y_train)[train_index], np.array(y_train)[test_index]\n",
        "\n",
        "            estimator.fit(X_train_fold, y_train_fold)\n",
        "            # Evaluation\n",
        "            y_pred = crf.predict(X_val_fold)\n",
        "            \n",
        "            # Calculate evaluation metrics for the current fold\n",
        "            report = classification_report(flatten(y_val_fold), flatten(y_pred), digits =5)\n",
        "            print(\"******************* Report of Fold\", f+1, \"*******************\")\n",
        "            print(report)\n",
        "            # Extract precision, recall, and F1-score from the classification report\n",
        "            metrics = report.split()[-4:]\n",
        "            f1_scores = (float(metrics[2]))\n",
        "            cv_results.append(f1_scores)\n",
        "            print(\"F1_Score of Fold\", f+1, \" = \", f1_scores)\n",
        "            f+=1\n",
        "\n",
        "        mean_score = np.mean(cv_results)\n",
        "        print(\"Mean of F1_Scores of iteration\", it, \"= \", mean_score, \"\\n\")\n",
        "        if best_score is None or mean_score > best_score:\n",
        "            best_score = mean_score\n",
        "            best_params = (c_one, c_two)\n",
        "            print(\"#### Best C1 and C2: \", best_params, \"####\")\n",
        "        it +=1\n",
        "\n",
        "    estimator.fit(X_train, y_train)\n",
        "\n",
        "    return estimator, best_params"
      ],
      "metadata": {
        "id": "ZhxP-zhlM1PC"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params_space = { 'c1': scipy.stats.expon(scale=0.25), 'c2': scipy.stats.expon(scale=0.5)}\n",
        "\n",
        "kfold = KFold(n_splits=6, shuffle=True)\n",
        "\n",
        "trained_model, best_c1c2 = randomized_search_cv(params_space, full_set, full_label, n_iter=5, cv=kfold)\n",
        "print(best_c1c2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1udG9eD9cq3",
        "outputId": "1447b027-e854-46a2-d509-5794a96a261b"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§ Iteration  0 §§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§\n",
            "******************* Report of Fold 1 *******************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC    0.27000   0.10037   0.14634       269\n",
            "      B-MISC    0.30769   0.18293   0.22945       328\n",
            "       B-ORG    0.23785   0.16368   0.19391       837\n",
            "       B-PER    0.51150   0.53527   0.52311      1205\n",
            "       I-LOC    0.28384   0.07567   0.11949       859\n",
            "       I-ORG    0.40330   0.31334   0.35267      1717\n",
            "       I-PER    0.35006   0.17824   0.23621      1526\n",
            "           O    0.91069   0.96830   0.93861     41417\n",
            "         PER    0.49102   0.38886   0.43401      1687\n",
            "\n",
            "    accuracy                        0.85272     49845\n",
            "   macro avg    0.41844   0.32296   0.35264     49845\n",
            "weighted avg    0.82267   0.85272   0.83424     49845\n",
            "\n",
            "F1_Score of Fold 1  =  0.83424\n",
            "******************* Report of Fold 2 *******************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC    0.34615   0.15517   0.21429       290\n",
            "      B-MISC    0.25000   0.13858   0.17831       267\n",
            "       B-ORG    0.27211   0.16895   0.20847       947\n",
            "       B-PER    0.50249   0.54260   0.52178      1115\n",
            "       I-LOC    0.29612   0.07341   0.11765       831\n",
            "       I-ORG    0.38836   0.29808   0.33728      1768\n",
            "       I-PER    0.36449   0.17191   0.23363      1588\n",
            "           O    0.90957   0.96993   0.93878     42175\n",
            "         PER    0.48868   0.37802   0.42629      1656\n",
            "\n",
            "    accuracy                        0.85394     50637\n",
            "   macro avg    0.42422   0.32185   0.35294     50637\n",
            "weighted avg    0.82286   0.85394   0.83443     50637\n",
            "\n",
            "F1_Score of Fold 2  =  0.83443\n",
            "******************* Report of Fold 3 *******************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC    0.31579   0.08922   0.13913       269\n",
            "      B-MISC    0.19880   0.10963   0.14133       301\n",
            "       B-ORG    0.26876   0.18849   0.22158       817\n",
            "       B-PER    0.51186   0.56936   0.53908      1175\n",
            "       I-LOC    0.33824   0.07922   0.12837       871\n",
            "       I-ORG    0.42358   0.30847   0.35698      1770\n",
            "       I-PER    0.37517   0.18129   0.24445      1550\n",
            "           O    0.91171   0.97148   0.94065     41861\n",
            "         PER    0.49709   0.39515   0.44030      1731\n",
            "\n",
            "    accuracy                        0.85663     50345\n",
            "   macro avg    0.42678   0.32137   0.35021     50345\n",
            "weighted avg    0.82664   0.85663   0.83733     50345\n",
            "\n",
            "F1_Score of Fold 3  =  0.83733\n",
            "******************* Report of Fold 4 *******************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC    0.34483   0.14085   0.20000       284\n",
            "      B-MISC    0.21512   0.15612   0.18093       237\n",
            "       B-ORG    0.28500   0.19907   0.23441       859\n",
            "       B-PER    0.52525   0.56522   0.54450      1196\n",
            "       I-LOC    0.30542   0.07407   0.11923       837\n",
            "       I-ORG    0.42564   0.31119   0.35953      1867\n",
            "       I-PER    0.39001   0.19126   0.25666      1511\n",
            "           O    0.91176   0.96932   0.93966     41690\n",
            "         PER    0.50852   0.40980   0.45385      1674\n",
            "\n",
            "    accuracy                        0.85641     50155\n",
            "   macro avg    0.43462   0.33521   0.36542     50155\n",
            "weighted avg    0.82791   0.85641   0.83831     50155\n",
            "\n",
            "F1_Score of Fold 4  =  0.83831\n",
            "******************* Report of Fold 5 *******************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC    0.34862   0.12625   0.18537       301\n",
            "      B-MISC    0.22034   0.12745   0.16149       306\n",
            "       B-ORG    0.29899   0.19710   0.23758       898\n",
            "       B-PER    0.52644   0.57863   0.55130      1170\n",
            "       I-LOC    0.23423   0.06388   0.10039       814\n",
            "       I-ORG    0.42601   0.30271   0.35393      1807\n",
            "       I-PER    0.37913   0.18612   0.24967      1542\n",
            "           O    0.90978   0.97009   0.93897     41330\n",
            "         PER    0.50000   0.40284   0.44619      1693\n",
            "\n",
            "    accuracy                        0.85423     49861\n",
            "   macro avg    0.42706   0.32834   0.35832     49861\n",
            "weighted avg    0.82328   0.85423   0.83498     49861\n",
            "\n",
            "F1_Score of Fold 5  =  0.83498\n",
            "******************* Report of Fold 6 *******************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC    0.27869   0.13178   0.17895       258\n",
            "      B-MISC    0.28571   0.17266   0.21525       278\n",
            "       B-ORG    0.31269   0.22210   0.25972       932\n",
            "       B-PER    0.49719   0.54779   0.52126      1130\n",
            "       I-LOC    0.32487   0.07529   0.12225       850\n",
            "       I-ORG    0.39985   0.31061   0.34962      1716\n",
            "       I-PER    0.37516   0.18804   0.25052      1606\n",
            "           O    0.91458   0.96952   0.94125     42187\n",
            "         PER    0.47126   0.38504   0.42381      1618\n",
            "\n",
            "    accuracy                        0.85677     50575\n",
            "   macro avg    0.42889   0.33365   0.36251     50575\n",
            "weighted avg    0.82878   0.85677   0.83910     50575\n",
            "\n",
            "F1_Score of Fold 6  =  0.8391\n",
            "Mean of F1_Scores of iteration 0 =  0.8363983333333334 \n",
            "\n",
            "#### Best C1 and C2:  (0.044936331759601045, 1.1334680353495603) ####\n",
            "\n",
            "\n",
            "§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§ Iteration  1 §§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§\n",
            "******************* Report of Fold 1 *******************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC    0.30769   0.10997   0.16203       291\n",
            "      B-MISC    0.18621   0.10000   0.13012       270\n",
            "       B-ORG    0.28918   0.18902   0.22861       947\n",
            "       B-PER    0.50945   0.56066   0.53383      1154\n",
            "       I-LOC    0.25253   0.06090   0.09814       821\n",
            "       I-ORG    0.40570   0.30873   0.35063      1707\n",
            "       I-PER    0.39948   0.18866   0.25628      1622\n",
            "           O    0.90967   0.96840   0.93812     41900\n",
            "         PER    0.49174   0.40283   0.44287      1626\n",
            "\n",
            "    accuracy                        0.85421     50338\n",
            "   macro avg    0.41685   0.32102   0.34896     50338\n",
            "weighted avg    0.82372   0.85421   0.83509     50338\n",
            "\n",
            "F1_Score of Fold 1  =  0.83509\n",
            "******************* Report of Fold 2 *******************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC    0.30973   0.12456   0.17766       281\n",
            "      B-MISC    0.21579   0.13851   0.16872       296\n",
            "       B-ORG    0.31126   0.23559   0.26819       798\n",
            "       B-PER    0.51738   0.54468   0.53068      1175\n",
            "       I-LOC    0.29187   0.07085   0.11402       861\n",
            "       I-ORG    0.43832   0.32351   0.37227      1867\n",
            "       I-PER    0.36063   0.18699   0.24628      1460\n",
            "           O    0.91244   0.96946   0.94008     42006\n",
            "         PER    0.49810   0.38757   0.43594      1690\n",
            "\n",
            "    accuracy                        0.85696     50434\n",
            "   macro avg    0.42839   0.33130   0.36154     50434\n",
            "weighted avg    0.82827   0.85696   0.83904     50434\n",
            "\n",
            "F1_Score of Fold 2  =  0.83904\n",
            "******************* Report of Fold 3 *******************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC    0.24561   0.10036   0.14249       279\n",
            "      B-MISC    0.27174   0.17007   0.20921       294\n",
            "       B-ORG    0.25743   0.18267   0.21370       854\n",
            "       B-PER    0.52581   0.55254   0.53884      1180\n",
            "       I-LOC    0.31019   0.07892   0.12582       849\n",
            "       I-ORG    0.39007   0.27623   0.32342      1792\n",
            "       I-PER    0.36789   0.18982   0.25043      1533\n",
            "           O    0.91055   0.97084   0.93973     41900\n",
            "         PER    0.50958   0.38708   0.43996      1718\n",
            "\n",
            "    accuracy                        0.85482     50399\n",
            "   macro avg    0.42098   0.32317   0.35373     50399\n",
            "weighted avg    0.82427   0.85482   0.83574     50399\n",
            "\n",
            "F1_Score of Fold 3  =  0.83574\n",
            "******************* Report of Fold 4 *******************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC    0.40625   0.15600   0.22543       250\n",
            "      B-MISC    0.26705   0.15615   0.19706       301\n",
            "       B-ORG    0.28344   0.20366   0.23702       874\n",
            "       B-PER    0.51633   0.59286   0.55195      1120\n",
            "       I-LOC    0.33621   0.09070   0.14286       860\n",
            "       I-ORG    0.42513   0.31406   0.36125      1799\n",
            "       I-PER    0.38757   0.18533   0.25075      1581\n",
            "           O    0.91227   0.96909   0.93982     41344\n",
            "         PER    0.48900   0.40253   0.44158      1657\n",
            "\n",
            "    accuracy                        0.85560     49786\n",
            "   macro avg    0.44703   0.34115   0.37197     49786\n",
            "weighted avg    0.82758   0.85560   0.83754     49786\n",
            "\n",
            "F1_Score of Fold 4  =  0.83754\n",
            "******************* Report of Fold 5 *******************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC    0.31304   0.12287   0.17647       293\n",
            "      B-MISC    0.24074   0.13684   0.17450       285\n",
            "       B-ORG    0.24532   0.15335   0.18873       939\n",
            "       B-PER    0.49139   0.55379   0.52073      1134\n",
            "       I-LOC    0.26257   0.05556   0.09171       846\n",
            "       I-ORG    0.38784   0.30385   0.34075      1764\n",
            "       I-PER    0.33377   0.16146   0.21763      1567\n",
            "           O    0.91053   0.96888   0.93880     41773\n",
            "         PER    0.47973   0.39052   0.43056      1667\n",
            "\n",
            "    accuracy                        0.85158     50268\n",
            "   macro avg    0.40722   0.31635   0.34221     50268\n",
            "weighted avg    0.81985   0.85158   0.83200     50268\n",
            "\n",
            "F1_Score of Fold 5  =  0.832\n",
            "******************* Report of Fold 6 *******************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC    0.34234   0.13718   0.19588       277\n",
            "      B-MISC    0.29586   0.18450   0.22727       271\n",
            "       B-ORG    0.29433   0.18337   0.22596       878\n",
            "       B-PER    0.51603   0.53746   0.52653      1228\n",
            "       I-LOC    0.30837   0.08485   0.13308       825\n",
            "       I-ORG    0.41762   0.31760   0.36081      1716\n",
            "       I-PER    0.38400   0.18462   0.24935      1560\n",
            "           O    0.91267   0.97199   0.94139     41737\n",
            "         PER    0.49004   0.39036   0.43455      1701\n",
            "\n",
            "    accuracy                        0.85757     50193\n",
            "   macro avg    0.44014   0.33244   0.36609     50193\n",
            "weighted avg    0.82806   0.85757   0.83894     50193\n",
            "\n",
            "F1_Score of Fold 6  =  0.83894\n",
            "Mean of F1_Scores of iteration 1 =  0.8363916666666666 \n",
            "\n",
            "\n",
            "\n",
            "§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§ Iteration  2 §§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§\n",
            "******************* Report of Fold 1 *******************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC    0.35849   0.13523   0.19638       281\n",
            "      B-MISC    0.24852   0.14189   0.18065       296\n",
            "       B-ORG    0.21978   0.16827   0.19061       832\n",
            "       B-PER    0.50554   0.57880   0.53970      1104\n",
            "       I-LOC    0.35096   0.08701   0.13945       839\n",
            "       I-ORG    0.42041   0.31029   0.35705      1779\n",
            "       I-PER    0.34446   0.17281   0.23015      1493\n",
            "           O    0.91398   0.96790   0.94017     41252\n",
            "         PER    0.48168   0.40427   0.43959      1593\n",
            "\n",
            "    accuracy                        0.85536     49469\n",
            "   macro avg    0.42709   0.32961   0.35708     49469\n",
            "weighted avg    0.82764   0.85536   0.83776     49469\n",
            "\n",
            "F1_Score of Fold 1  =  0.83776\n",
            "******************* Report of Fold 2 *******************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC    0.36752   0.13782   0.20047       312\n",
            "      B-MISC    0.24324   0.16071   0.19355       280\n",
            "       B-ORG    0.27441   0.17834   0.21618       914\n",
            "       B-PER    0.52329   0.57411   0.54752      1174\n",
            "       I-LOC    0.27273   0.06690   0.10745       852\n",
            "       I-ORG    0.41150   0.30493   0.35029      1784\n",
            "       I-PER    0.37403   0.17888   0.24202      1610\n",
            "           O    0.91296   0.97097   0.94107     42852\n",
            "         PER    0.50256   0.41662   0.45557      1649\n",
            "\n",
            "    accuracy                        0.85770     51427\n",
            "   macro avg    0.43136   0.33214   0.36157     51427\n",
            "weighted avg    0.82772   0.85770   0.83888     51427\n",
            "\n",
            "F1_Score of Fold 2  =  0.83888\n",
            "******************* Report of Fold 3 *******************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC    0.33333   0.12274   0.17942       277\n",
            "      B-MISC    0.23669   0.13605   0.17279       294\n",
            "       B-ORG    0.31676   0.19369   0.24039       888\n",
            "       B-PER    0.51202   0.53562   0.52356      1193\n",
            "       I-LOC    0.27727   0.07332   0.11597       832\n",
            "       I-ORG    0.40672   0.29994   0.34526      1817\n",
            "       I-PER    0.37451   0.18176   0.24474      1568\n",
            "           O    0.90957   0.97101   0.93929     41600\n",
            "         PER    0.48915   0.39374   0.43629      1661\n",
            "\n",
            "    accuracy                        0.85426     50130\n",
            "   macro avg    0.42845   0.32310   0.35530     50130\n",
            "weighted avg    0.82309   0.85426   0.83473     50130\n",
            "\n",
            "F1_Score of Fold 3  =  0.83473\n",
            "******************* Report of Fold 4 *******************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC    0.32773   0.14885   0.20472       262\n",
            "      B-MISC    0.29193   0.16906   0.21412       278\n",
            "       B-ORG    0.34138   0.20952   0.25967       945\n",
            "       B-PER    0.53877   0.55630   0.54739      1199\n",
            "       I-LOC    0.32883   0.08711   0.13774       838\n",
            "       I-ORG    0.39466   0.30912   0.34669      1721\n",
            "       I-PER    0.38794   0.18535   0.25085      1597\n",
            "           O    0.90973   0.97066   0.93921     41926\n",
            "         PER    0.52181   0.39977   0.45270      1706\n",
            "\n",
            "    accuracy                        0.85651     50472\n",
            "   macro avg    0.44920   0.33731   0.37257     50472\n",
            "weighted avg    0.82702   0.85651   0.83764     50472\n",
            "\n",
            "F1_Score of Fold 4  =  0.83764\n",
            "******************* Report of Fold 5 *******************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC    0.24419   0.07216   0.11141       291\n",
            "      B-MISC    0.21250   0.12734   0.15925       267\n",
            "       B-ORG    0.28148   0.21158   0.24158       898\n",
            "       B-PER    0.49961   0.55633   0.52645      1154\n",
            "       I-LOC    0.24242   0.05783   0.09339       830\n",
            "       I-ORG    0.42210   0.30573   0.35461      1799\n",
            "       I-PER    0.37677   0.18493   0.24809      1579\n",
            "           O    0.91063   0.97013   0.93944     41444\n",
            "         PER    0.48176   0.37726   0.42315      1715\n",
            "\n",
            "    accuracy                        0.85299     49977\n",
            "   macro avg    0.40794   0.31814   0.34415     49977\n",
            "weighted avg    0.82196   0.85299   0.83371     49977\n",
            "\n",
            "F1_Score of Fold 5  =  0.83371\n",
            "******************* Report of Fold 6 *******************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC    0.26829   0.13306   0.17790       248\n",
            "      B-MISC    0.25275   0.15232   0.19008       302\n",
            "       B-ORG    0.25445   0.17589   0.20800       813\n",
            "       B-PER    0.49724   0.53985   0.51767      1167\n",
            "       I-LOC    0.29902   0.07003   0.11349       871\n",
            "       I-ORG    0.41093   0.31461   0.35638      1745\n",
            "       I-PER    0.37500   0.19309   0.25492      1476\n",
            "           O    0.91126   0.96792   0.93873     41586\n",
            "         PER    0.48093   0.37061   0.41862      1735\n",
            "\n",
            "    accuracy                        0.85381     49943\n",
            "   macro avg    0.41665   0.32415   0.35287     49943\n",
            "weighted avg    0.82476   0.85381   0.83568     49943\n",
            "\n",
            "F1_Score of Fold 6  =  0.83568\n",
            "Mean of F1_Scores of iteration 2 =  0.8363999999999999 \n",
            "\n",
            "#### Best C1 and C2:  (0.4528934415022353, 0.7250788576040323) ####\n",
            "\n",
            "\n",
            "§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§ Iteration  3 §§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§\n",
            "******************* Report of Fold 1 *******************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC    0.24427   0.11765   0.15881       272\n",
            "      B-MISC    0.24432   0.13738   0.17587       313\n",
            "       B-ORG    0.26325   0.19083   0.22126       807\n",
            "       B-PER    0.51860   0.54082   0.52948      1237\n",
            "       I-LOC    0.26214   0.06345   0.10218       851\n",
            "       I-ORG    0.40000   0.30719   0.34751      1849\n",
            "       I-PER    0.37467   0.18152   0.24456      1548\n",
            "           O    0.91196   0.96932   0.93977     42244\n",
            "         PER    0.50185   0.40142   0.44605      1689\n",
            "\n",
            "    accuracy                        0.85469     50810\n",
            "   macro avg    0.41345   0.32329   0.35172     50810\n",
            "weighted avg    0.82488   0.85469   0.83631     50810\n",
            "\n",
            "F1_Score of Fold 1  =  0.83631\n",
            "******************* Report of Fold 2 *******************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC    0.43478   0.13378   0.20460       299\n",
            "      B-MISC    0.24121   0.15738   0.19048       305\n",
            "       B-ORG    0.29340   0.18410   0.22624       918\n",
            "       B-PER    0.49675   0.55385   0.52375      1105\n",
            "       I-LOC    0.33333   0.08869   0.14011       902\n",
            "       I-ORG    0.40611   0.29821   0.34389      1784\n",
            "       I-PER    0.37348   0.17228   0.23580      1602\n",
            "           O    0.91137   0.97136   0.94041     43125\n",
            "         PER    0.47201   0.38188   0.42219      1634\n",
            "\n",
            "    accuracy                        0.85674     51674\n",
            "   macro avg    0.44027   0.32684   0.35861     51674\n",
            "weighted avg    0.82671   0.85674   0.83733     51674\n",
            "\n",
            "F1_Score of Fold 2  =  0.83733\n",
            "******************* Report of Fold 3 *******************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC    0.38835   0.15686   0.22346       255\n",
            "      B-MISC    0.18129   0.11314   0.13933       274\n",
            "       B-ORG    0.22819   0.14929   0.18049       911\n",
            "       B-PER    0.50117   0.53378   0.51696      1199\n",
            "       I-LOC    0.25758   0.06064   0.09817       841\n",
            "       I-ORG    0.42279   0.32267   0.36601      1782\n",
            "       I-PER    0.34783   0.18013   0.23735      1510\n",
            "           O    0.91059   0.96829   0.93855     41527\n",
            "         PER    0.48271   0.38475   0.42820      1705\n",
            "\n",
            "    accuracy                        0.85215     50004\n",
            "   macro avg    0.41339   0.31884   0.34761     50004\n",
            "weighted avg    0.82173   0.85215   0.83349     50004\n",
            "\n",
            "F1_Score of Fold 3  =  0.83349\n",
            "******************* Report of Fold 4 *******************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC    0.29661   0.11824   0.16908       296\n",
            "      B-MISC    0.35915   0.18280   0.24228       279\n",
            "       B-ORG    0.32953   0.22370   0.26649       903\n",
            "       B-PER    0.50407   0.54682   0.52458      1132\n",
            "       I-LOC    0.32632   0.07337   0.11981       845\n",
            "       I-ORG    0.43755   0.30749   0.36116      1857\n",
            "       I-PER    0.38630   0.19020   0.25490      1572\n",
            "           O    0.90900   0.97171   0.93931     41389\n",
            "         PER    0.48441   0.38466   0.42881      1656\n",
            "\n",
            "    accuracy                        0.85509     49929\n",
            "   macro avg    0.44811   0.33322   0.36738     49929\n",
            "weighted avg    0.82470   0.85509   0.83543     49929\n",
            "\n",
            "F1_Score of Fold 4  =  0.83543\n",
            "******************* Report of Fold 5 *******************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC    0.34286   0.12676   0.18509       284\n",
            "      B-MISC    0.21384   0.14407   0.17215       236\n",
            "       B-ORG    0.31664   0.21948   0.25926       893\n",
            "       B-PER    0.52986   0.58908   0.55790      1190\n",
            "       I-LOC    0.28365   0.07603   0.11992       776\n",
            "       I-ORG    0.42925   0.32264   0.36839      1683\n",
            "       I-PER    0.39198   0.19226   0.25798      1576\n",
            "           O    0.91382   0.96850   0.94036     41264\n",
            "         PER    0.51085   0.42402   0.46341      1665\n",
            "\n",
            "    accuracy                        0.85827     49567\n",
            "   macro avg    0.43697   0.34032   0.36938     49567\n",
            "weighted avg    0.83079   0.85827   0.84094     49567\n",
            "\n",
            "F1_Score of Fold 5  =  0.84094\n",
            "******************* Report of Fold 6 *******************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC    0.24038   0.09434   0.13550       265\n",
            "      B-MISC    0.26257   0.15161   0.19223       310\n",
            "       B-ORG    0.24751   0.17366   0.20411       858\n",
            "       B-PER    0.52419   0.57624   0.54899      1128\n",
            "       I-LOC    0.30594   0.07910   0.12570       847\n",
            "       I-ORG    0.37097   0.28580   0.32286      1690\n",
            "       I-PER    0.35921   0.18020   0.24000      1515\n",
            "           O    0.91139   0.96942   0.93951     41111\n",
            "         PER    0.50500   0.38363   0.43603      1710\n",
            "\n",
            "    accuracy                        0.85374     49434\n",
            "   macro avg    0.41413   0.32156   0.34944     49434\n",
            "weighted avg    0.82353   0.85374   0.83496     49434\n",
            "\n",
            "F1_Score of Fold 6  =  0.83496\n",
            "Mean of F1_Scores of iteration 3 =  0.83641 \n",
            "\n",
            "#### Best C1 and C2:  (0.13030191674624952, 0.22747553071996074) ####\n",
            "\n",
            "\n",
            "§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§ Iteration  4 §§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§§\n",
            "******************* Report of Fold 1 *******************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC    0.29808   0.10438   0.15461       297\n",
            "      B-MISC    0.22703   0.14433   0.17647       291\n",
            "       B-ORG    0.26853   0.18586   0.21968       877\n",
            "       B-PER    0.48718   0.56089   0.52144      1084\n",
            "       I-LOC    0.25225   0.06415   0.10228       873\n",
            "       I-ORG    0.40829   0.30193   0.34715      1762\n",
            "       I-PER    0.36649   0.18397   0.24497      1522\n",
            "           O    0.91308   0.96872   0.94008     42324\n",
            "         PER    0.46581   0.37793   0.41729      1622\n",
            "\n",
            "    accuracy                        0.85535     50652\n",
            "   macro avg    0.40964   0.32135   0.34711     50652\n",
            "weighted avg    0.82556   0.85535   0.83696     50652\n",
            "\n",
            "F1_Score of Fold 1  =  0.83696\n",
            "******************* Report of Fold 2 *******************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC    0.28571   0.10526   0.15385       285\n",
            "      B-MISC    0.26846   0.12270   0.16842       326\n",
            "       B-ORG    0.26657   0.21274   0.23663       832\n",
            "       B-PER    0.51280   0.58392   0.54606      1132\n",
            "       I-LOC    0.28019   0.06524   0.10584       889\n",
            "       I-ORG    0.38973   0.30389   0.34150      1698\n",
            "       I-PER    0.37687   0.19436   0.25645      1559\n",
            "           O    0.91466   0.96892   0.94101     41704\n",
            "         PER    0.50588   0.41571   0.45638      1655\n",
            "\n",
            "    accuracy                        0.85625     50080\n",
            "   macro avg    0.42232   0.33030   0.35624     50080\n",
            "weighted avg    0.82771   0.85625   0.83839     50080\n",
            "\n",
            "F1_Score of Fold 2  =  0.83839\n",
            "******************* Report of Fold 3 *******************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC    0.36449   0.15354   0.21607       254\n",
            "      B-MISC    0.24551   0.15129   0.18721       271\n",
            "       B-ORG    0.28281   0.18000   0.21999       850\n",
            "       B-PER    0.50578   0.57848   0.53970      1134\n",
            "       I-LOC    0.31188   0.07572   0.12186       832\n",
            "       I-ORG    0.42684   0.30900   0.35848      1822\n",
            "       I-PER    0.35441   0.17756   0.23659      1515\n",
            "           O    0.91116   0.96902   0.93920     41544\n",
            "         PER    0.49077   0.38957   0.43436      1707\n",
            "\n",
            "    accuracy                        0.85533     49929\n",
            "   macro avg    0.43263   0.33158   0.36149     49929\n",
            "weighted avg    0.82594   0.85533   0.83673     49929\n",
            "\n",
            "F1_Score of Fold 3  =  0.83673\n",
            "******************* Report of Fold 4 *******************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC    0.26613   0.12453   0.16967       265\n",
            "      B-MISC    0.25301   0.14583   0.18502       288\n",
            "       B-ORG    0.28319   0.20105   0.23515       955\n",
            "       B-PER    0.52923   0.52231   0.52575      1300\n",
            "       I-LOC    0.33962   0.08276   0.13309       870\n",
            "       I-ORG    0.37834   0.28571   0.32557      1785\n",
            "       I-PER    0.37611   0.18340   0.24656      1614\n",
            "           O    0.90783   0.96964   0.93772     42554\n",
            "         PER    0.49486   0.37865   0.42903      1780\n",
            "\n",
            "    accuracy                        0.85118     51411\n",
            "   macro avg    0.42537   0.32154   0.35417     51411\n",
            "weighted avg    0.82069   0.85118   0.83189     51411\n",
            "\n",
            "F1_Score of Fold 4  =  0.83189\n",
            "******************* Report of Fold 5 *******************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC    0.30769   0.12811   0.18090       281\n",
            "      B-MISC    0.28333   0.20238   0.23611       252\n",
            "       B-ORG    0.30899   0.18072   0.22806       913\n",
            "       B-PER    0.49628   0.52952   0.51236      1135\n",
            "       I-LOC    0.30732   0.07935   0.12613       794\n",
            "       I-ORG    0.43703   0.32790   0.37468      1778\n",
            "       I-PER    0.38889   0.18758   0.25309      1530\n",
            "           O    0.91176   0.97081   0.94036     41178\n",
            "         PER    0.47715   0.38645   0.42704      1594\n",
            "\n",
            "    accuracy                        0.85690     49455\n",
            "   macro avg    0.43538   0.33254   0.36430     49455\n",
            "weighted avg    0.82750   0.85690   0.83826     49455\n",
            "\n",
            "F1_Score of Fold 5  =  0.83826\n",
            "******************* Report of Fold 6 *******************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC    0.40625   0.13495   0.20260       289\n",
            "      B-MISC    0.21229   0.13149   0.16239       289\n",
            "       B-ORG    0.27513   0.18076   0.21818       863\n",
            "       B-PER    0.54358   0.56882   0.55592      1206\n",
            "       I-LOC    0.28638   0.07587   0.11996       804\n",
            "       I-ORG    0.42579   0.31556   0.36248      1800\n",
            "       I-PER    0.37052   0.16993   0.23300      1583\n",
            "           O    0.90969   0.97159   0.93962     41356\n",
            "         PER    0.52158   0.41211   0.46043      1701\n",
            "\n",
            "    accuracy                        0.85585     49891\n",
            "   macro avg    0.43902   0.32901   0.36162     49891\n",
            "weighted avg    0.82506   0.85585   0.83631     49891\n",
            "\n",
            "F1_Score of Fold 6  =  0.83631\n",
            "Mean of F1_Scores of iteration 4 =  0.8364233333333334 \n",
            "\n",
            "#### Best C1 and C2:  (0.13509552546798886, 0.7231664485075496) ####\n",
            "(0.13509552546798886, 0.7231664485075496)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_crf = CRF(algorithm='lbfgs', c1= best_c1c2[0], c2= best_c1c2[1], max_iterations=300, all_possible_transitions=True)"
      ],
      "metadata": {
        "id": "hJIwM3k1-Uzq"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = trained_model.predict(test_ner)\n",
        "print(test_label_ner[0])\n",
        "print(y_pred[0])\n",
        "# Calculate evaluation metrics\n",
        "report = classification_report(flatten(test_label_ner), flatten(y_pred), digits=3)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HSyOZeYKIat",
        "outputId": "24366e41-269b-405b-b9e2-73b780254cf7"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['O', 'O', 'I-ORG', 'O', 'O', 'O', 'O', 'PER', 'O', 'O', 'O', 'O']\n",
            "['I-PER', 'O', 'I-ORG', 'O', 'I-PER', 'B-ORG', 'O', 'I-ORG', 'O', 'I-ORG', 'O', 'O']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC      0.323     0.121     0.176       257\n",
            "      B-MISC      0.203     0.199     0.201       216\n",
            "       B-ORG      0.254     0.169     0.203       835\n",
            "       B-PER      0.528     0.556     0.542      1156\n",
            "       I-LOC      0.266     0.077     0.119       702\n",
            "       I-ORG      0.396     0.304     0.344      1668\n",
            "       I-PER      0.400     0.203     0.269      1661\n",
            "           O      0.908     0.966     0.936     38323\n",
            "         PER      0.517     0.404     0.454      1617\n",
            "\n",
            "    accuracy                          0.849     46435\n",
            "   macro avg      0.422     0.333     0.360     46435\n",
            "weighted avg      0.821     0.849     0.831     46435\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OP7b3PBMLYY3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}